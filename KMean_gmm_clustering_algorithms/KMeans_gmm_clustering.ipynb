{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Optimum Number of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that K-Means and Gaussian Mixture Modelling models are working efficiently we need to provide them with a starting number of clusters. If the number of clusters is incorrectly selected, the algorithms may not perform well.\n",
    "\n",
    "We can attempt to identify the optimum number of clusters using an elblow plot, where the goal is to select a number for the clusters based on the ‘elbow’ or inflexion formed in the results. There are other methods such as the silhouette method for picking the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_k_means(data, max_k):\n",
    "    means = []\n",
    "    inertias = []\n",
    "    \n",
    "    for k in tqdm(range(1,max_k)):\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(data)\n",
    "        means.append(k)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        \n",
    "    fig = plt.subplots(figsize=(10, 5))\n",
    "    plt.plot(means, inertias, 'o-')\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Inertia\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimise_k_means(df, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the In plot above, we can see how the inertia (sum of the squared distances to the nearest cluster center) changes as we increase the number of clusters. Therefore we can find out at which point the slope is changing drastically. That point can be show an approximate of the number of clusters in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Clustering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the KMeans model with the selected number of clusters\n",
    "kmeans = KMeans(n_clusters=4) # 4 is an example\n",
    "\n",
    "# Fit the model to our dataset\n",
    "kmeans.fit(df)\n",
    "\n",
    "# Assign the data back to the df\n",
    "df['KMeans'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gmm model with the selected number of clusters/components\n",
    "gmm = GaussianMixture(n_components=4) # 4 is an example\n",
    "\n",
    "# Fit the model to our dataset\n",
    "gmm.fit(df)\n",
    "\n",
    "# Predict the labels\n",
    "gmm_labels = gmm.predict(df)\n",
    "\n",
    "# Assign the labels back to the df\n",
    "df['GMM'] = gmm_labels"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
